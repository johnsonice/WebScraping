十年前，我写了一本书。
书名为《 我们的末世纪？》以问号结尾。
我的出版商去掉了问号。（笑声）
美国出版商把我们的书名
改成了《我们的末日》。
美国人喜欢即刻的满足与逆反。
（笑声）
我的主题是这样的，
我们的地球已经存在了四千五百多万个世纪。
但这个世纪是特殊的，
第一次有一个物种，也就是我们，
掌握了这个星球的命运。
地球过去的历史中，
威胁主要来源于自然——
疾病、地震、小行星等等——
但是从今往后，最大的威胁来源于我们自己。
现今不止是核威胁，
在这个相互连接的世界裡，
网路故障可以波及全球，
航空旅行可以在几天内将流行病传遍世界。
社会媒体简直能以光速
散播恐慌和谣言。
我们太过苦恼于那些次要的危害，
像是发生概率极小的空难、食品中的致癌物、
低辐射等等。
但我们和政治领袖们
却否认那些灾难性的情节。
幸运的是最可怕的事情还没有发生，
的确，他们可能不会发生。
但是如果有一件事具潜在的毁灭性，
那就值得我们付出大量的精力与金钱。
把它掐死在摇篮裡，即使它不太可能发生。
这就像给我们的房子买火灾险。
科学提供了更强大的力量和保证，
随之而来的负面影响也变得更加可怕，
我们变得更加脆弱。
数十年之内，
数百万人将会有能力
滥用飞速发展的生物技术，
就像他们今天滥用网路技术一样。
费裡曼•戴森在TED演讲中
预言孩子们会设计并创造新的有机体，
就像他们那一代人摆弄化学装置一样平常。
好吧，这大概已经到科幻小说的边缘了，
但是即使他情节中一小部份发生了，
我们的生态系统乃至整个人类种族
必定不会安然无恙地存活太久。
比如说，有一些生态极端主义者
认为如果能大大减少人口，
那会对这整个星球和大地母亲更好。
当这样的人掌握了
那些将在2050年普及的合成生物技术，
会发生什麽？
到那时，其他科幻小说中的噩梦
也可能变为现实。
成了流氓的愚蠢机器人
或者一套发展出自我意识的网路系统
威胁我们所有人。
那麽，我们能不能通过条例来防范这样的风险？
无疑我们必将尝试，
但那些企业是如此求胜心切，
如此全球化，如此被商业压力所驱使，
以至于他们会不择手段，
不管法规条例说了些什麽。
这就像製毒法律——我们试图管制，但做不到。
地球村裡将会有些愚蠢的村民，
影响到整个地球。
所以就像我在书中所说，
我们会在颠簸中走完这个世纪。
我们的社会可能会遭遇挫折——
事实上，有 50% 的机率是极其严重的挫折。
但是，能否想像
更糟糕的事件，
那些可以毁灭所有生命的事件？
当一台新的粒子加速器开始运行时，
有人焦急地问
它会毁灭地球吗？
或者更糟，撕破时空的结构？
幸运的是对此我们可以放心，
我和其他一些人指出
大自然已经将同样的实验
通过宇宙射线的撞击
做了无数次。
但是对于那些在自然界中
没有先例的实验，
科学家们应该警钟长鸣，
生物学家应该预防
具有潜在毁灭性的转基因病原体。
顺便说一句，我们对于
毁灭性灾难的风险尤其反感，
这是基于一个哲学伦理问题。
这个问题是这样的。
想像如下两个场景：
情景 A：90%的人类会消亡；
情景 B：100%的人类会消亡。
情景 B 比情景 A 糟糕多少呢？
有人会说糟糕 10%，
因为死亡人数多 10%。
但我坚持情景 B 是无比糟糕的。
做为天文学家，我无法相信
人类是整个故事的结尾。
在太阳开始燃烧的五十亿年前，宇宙就诞生了，
而且可能会永远持续下去。
因此，在地球和及其遥远的地方，
后人类的进化会被延长，
就像产生了我们人类的式的达尔文式进化过程，
甚至更加绝妙。
事实上，未来的进化会发生得更快，
会在一个技术时间尺度上，
而不是一个自然选择的时间尺度上。
所以，考虑到这些重大的利害关係，
我们不应该接受哪怕十亿分之一的风险，
因人类灭绝而中止了
这巨大潜力的风险。
有些设想中的情景
的确可能只会在科幻小说裡出现，
但其他的一些可能会是令人不安的现实。
一句重要的格言这麽说：
不熟悉不等于不可能。
事实上，这就是为什麽我们正在剑桥大学
创建一个中心来研究
如何缓解这些生存风险。
看来让一小部分人
思考这些潜在灾难是值得的。
我们需要可以从其他人那裡得到的所有帮助。
因为我们是来自茫茫宇宙中
那颗珍贵暗蓝色圆石上的守护者，
一颗已经走过五千多万个世纪的星球，
所以请我们不要危及它的未来。
我想用一段伟大科学家彼得•梅达沃的话
结束今天的演讲，这段话是这样的：
「为人类敲响的钟
就像阿尔卑斯山上牛的铃铛，
繫在我们自己的脖子上。
如果它们没有发出和谐悠扬的乐声，
那一定是我们自己的错。」
非常感谢。
（掌声）