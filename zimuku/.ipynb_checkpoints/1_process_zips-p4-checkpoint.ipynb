{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unpack all zip and rar files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "from os import path\n",
    "import patoolib               #for unpacking\n",
    "from pyunpack import Archive  # for unpacking\n",
    "from shutil import copyfile\n",
    "import pysrt\n",
    "from mafan import simplify\n",
    "from guess_language import guess_language\n",
    "from itertools import compress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### go here to install guess_language : https://bitbucket.org/spirit/guess_language \n",
    "\n",
    "##### instructions for apt-get packages not available \n",
    "##### http://askubuntu.com/questions/283020/ubuntu-12-04-package-issues\n",
    "##### follow https://github.com/ponty/pyunpack to install pyunpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check(f):\n",
    "    filename, file_extension = os.path.splitext(f)\n",
    "    if file_extension == '.zip' or file_extension == '.rar' or file_extension == '.7z':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def check_dir(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)        # If not create the directory, inside their home directory\n",
    "        return True\n",
    "    \n",
    "def check_srt(f):\n",
    "    filename, file_extension = os.path.splitext(f)\n",
    "    if file_extension == '.srt':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def check_ass(f):\n",
    "    filename, file_extension = os.path.splitext(f)\n",
    "    if file_extension == '.ass':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "## use either gbk or big5 or utf-8\n",
    "def open_srt(f):\n",
    "    try:\n",
    "        some_subs = pysrt.open(f,encoding = 'gbk') \n",
    "        return some_subs\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        some_subs = pysrt.open(f,encoding = 'big5') \n",
    "        return some_subs\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        some_subs = pysrt.open(f) \n",
    "        return some_subs\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return None\n",
    "\n",
    "def validate(srt):\n",
    "    subs = open_srt(srt) \n",
    "    if subs is not None:\n",
    "        languages = [process_language(ele) for ele in subs]\n",
    "        return languages\n",
    "    else:\n",
    "        #print('Can not decode.')\n",
    "        return None\n",
    "    \n",
    "def replace_special(line_str):\n",
    "    line_str = re.sub('[『』【】「」♫．#♪]','',line_str)\n",
    "    line_str = re.sub(r'\\{.*?\\}','',line_str)     # non greedy match \n",
    "    line_str = re.sub(r'\\<.*?\\>','',line_str)     # non greedy match \n",
    "    return line_str \n",
    "\n",
    "def check_chinese(text):\n",
    "    ch = re.findall(r'[\\u4e00-\\u9fff]+', text)\n",
    "    return ch\n",
    "def check_english(text):\n",
    "    en = re.findall(r\"[A-Za-z]+\", text)\n",
    "    return en\n",
    "\n",
    "def process_language(ele):\n",
    "    try:\n",
    "        text_list = ele.text.split('\\n')\n",
    "        text_list = [replace_special(x) for x in text_list]\n",
    "        languages = [guess_language(l) for l in text_list]\n",
    "        en_index = [l=='en' for l in languages]\n",
    "        zh_index = [l=='zh' for l in languages]\n",
    "        en_lines = list(compress(text_list,en_index))\n",
    "        zh_lines = list(compress(text_list,zh_index))\n",
    "        if len(en_lines)==0 or len(zh_lines)==0:\n",
    "            return None\n",
    "        en_text = ' '.join(en_lines)\n",
    "        if len(check_chinese(en_text)) > 0:\n",
    "            return None \n",
    "        zh_text = simplify(' '.join(zh_lines))\n",
    "        if len(check_english(zh_text))>0:\n",
    "            return None\n",
    "        text_line = en_text + ' | ' + zh_text\n",
    "        return text_line\n",
    "    except:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "process_folder = 'data/process4/'\n",
    "\n",
    "data_raw = process_folder + 'data_download/'\n",
    "data_unpack = process_folder + 'data_unpack/'\n",
    "data_srt = process_folder + 'data_srt/'\n",
    "data_ass = process_folder + 'data_ass/'\n",
    "results_raw = process_folder + 'data_results_srt/'\n",
    "\n",
    "folders = [process_folder,data_raw,data_unpack,data_srt,data_ass,results_raw]\n",
    "[check_dir(x) for x in folders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "links = os.listdir(data_raw)\n",
    "files = [f for f in links if check(f)]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### if there are too many files, set it to run part of it forst \n",
    "#files = files[40000:60000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## unpack all the data\n",
    "for index,f in enumerate(files):\n",
    "    try:\n",
    "        f_name,f_ext = os.path.splitext(f)\n",
    "        Archive(data_raw+f).extractall(data_unpack)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## get all srt files, including files in subfolders \n",
    "## get all ass files, influding files in sub folders \n",
    "unpack_links = []\n",
    "unpack_names = []\n",
    "for path, subdirs, files in os.walk(data_unpack):\n",
    "    for name in files:\n",
    "        unpack_links.append(os.path.join(path, name))\n",
    "        unpack_names.append(name)\n",
    "#unpack_links = os.listdir(data_unpack)\n",
    "pair = zip(unpack_links,unpack_names)\n",
    "asss = [f for f in pair if check_ass(f[0])]\n",
    "pair = zip(unpack_links,unpack_names)\n",
    "srts = [f for f in pair if check_srt(f[0])]\n",
    "if len(srts)>0:\n",
    "    [copyfile(f[0],data_srt+f[1]) for f in srts]\n",
    "if len(asss)>0:\n",
    "    [copyfile(f[0],data_ass+f[1]) for f in asss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## search for srts with both chinese and english in it\n",
    "## and transform them into txt, seperated by |, dump to results raw\n",
    "data_srts = [data_srt + f for f in os.listdir(data_srt)]\n",
    "counter = 0 \n",
    "for index, srt in enumerate(data_srts):\n",
    "    res = validate(srt)\n",
    "    if res is not None: \n",
    "        total = len(res)\n",
    "        ## we only gonna to use files with both english and chinese in it \n",
    "        if total > 0:\n",
    "            none_values = sum([x is None for x in res ])\n",
    "            ratio = float(none_values)/float(total)\n",
    "            if ratio > 0.5:  \n",
    "                pass         \n",
    "            else:\n",
    "                res = res[5:-5]\n",
    "                res = [x for x in res if x is not None]\n",
    "                counter+=1\n",
    "                filename, file_extension = os.path.splitext(srt)\n",
    "                fname = filename.split('/')[-1]\n",
    "                fname = results_raw + str(counter)+'_'+fname+'.txt'\n",
    "                with open(fname, mode='wt', encoding='utf-8') as myfile:\n",
    "                    myfile.write('\\n'.join(res))\n",
    "                #print(res)\n",
    "                if counter%50 == 0:\n",
    "                    print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
