{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Get all links for zimuku items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "## send the request\n",
    "url = \"http://www.zimuku.net/search?q=&t=onlyst\"\n",
    "result = requests.get(url)\n",
    "print(result.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12993\n"
     ]
    }
   ],
   "source": [
    "## get page number\n",
    "c = result.content\n",
    "soup = BeautifulSoup(c,\"lxml\")\n",
    "pages =  soup.find('div',{'class':'pagination r clearfix'}).find('div')\n",
    "page_num = pages.findAll('a')[-1].getText()\n",
    "page_num = int(page_num)\n",
    "print(page_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## get download link from title link \n",
    "def get_down_link(url):\n",
    "    #url = \"http://www.zimuku.net/shooter/57265.html\"\n",
    "    try:\n",
    "        result = requests.get(url)\n",
    "        if result.status_code != 200:\n",
    "            return None\n",
    "        c = result.content\n",
    "        soup = BeautifulSoup(c,\"lxml\")\n",
    "        down_link =  soup.find('li',{'class':'li dlsub'}).find('a').get('href')\n",
    "        return down_link\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "## create doc_list to hold all links \n",
    "doc_list = {'title':[],'link':[]}\n",
    "page_num = 100\n",
    "## loop through each page\n",
    "for p in range(1,page_num+1):\n",
    "    try:\n",
    "        page_url = url + '&p=' + str(p)\n",
    "        result = requests.get(page_url)\n",
    "        #print(result.status_code)\n",
    "        c = result.content\n",
    "        soup = BeautifulSoup(c,\"lxml\")\n",
    "        docs = soup.find('div',{'class':'box clearfix'}).findAll('div',{'class':'persub clearfix'})\n",
    "\n",
    "        for doc in docs:\n",
    "\n",
    "            ## get title \n",
    "            link_tag = doc.find('h1',{'class':'title'}).find('a')\n",
    "            title = link_tag.getText().strip(' \\t\\n\\r@').replace('\\n','').replace('\\r',' ')\n",
    "            if title == '_':\n",
    "                continue\n",
    "            elif \"/\" in title:\n",
    "                 title = title.split(\"/\")[0]\n",
    "\n",
    "            link='http://www.zimuku.net'+link_tag.get('href')\n",
    "\n",
    "            ## get download link \n",
    "            down_link = get_down_link(link)\n",
    "\n",
    "            doc_list['title'].append(title)\n",
    "            doc_list['link'].append(down_link)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "print(len(doc_list['link']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://shooter.zimuku.net/download/NTcwNjV8Z2x...</td>\n",
       "      <td>gladiator_2000_extended_subs_r3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://shooter.zimuku.net/download/NTM3OTV8QW5...</td>\n",
       "      <td>An_Inconvenient_Truth_2006_Subs_R3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://shooter.zimuku.net/download/Mzk2OHxkYXJ...</td>\n",
       "      <td>darkangel</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://shooter.zimuku.net/download/MjY2MjI3fGN...</td>\n",
       "      <td>chappie_tlr1_h1080p</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://shooter.zimuku.net/download/MjY2MjI2fE9...</td>\n",
       "      <td>Once_Upon_a_Time_in_America_1984_Extended_Blur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://shooter.zimuku.net/download/MjY2MjI1fDF...</td>\n",
       "      <td>Two.and.a.Half.Men.S12E04.720p.HDTV.X264-DIMEN...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  http://shooter.zimuku.net/download/NTcwNjV8Z2x...   \n",
       "1  http://shooter.zimuku.net/download/NTM3OTV8QW5...   \n",
       "2  http://shooter.zimuku.net/download/Mzk2OHxkYXJ...   \n",
       "3  http://shooter.zimuku.net/download/MjY2MjI3fGN...   \n",
       "4  http://shooter.zimuku.net/download/MjY2MjI2fE9...   \n",
       "5  http://shooter.zimuku.net/download/MjY2MjI1fDF...   \n",
       "\n",
       "                                               title  status  \n",
       "0                    gladiator_2000_extended_subs_r3       0  \n",
       "1                 An_Inconvenient_Truth_2006_Subs_R3       0  \n",
       "2                                          darkangel       0  \n",
       "3                                chappie_tlr1_h1080p       0  \n",
       "4  Once_Upon_a_Time_in_America_1984_Extended_Blur...       0  \n",
       "5  Two.and.a.Half.Men.S12E04.720p.HDTV.X264-DIMEN...       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## export links file \n",
    "df = pd.DataFrame(doc_list)\n",
    "df['status']= 0\n",
    "df.to_csv('zimuku_links.csv')\n",
    "df.ix[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now start downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## download \n",
    "def download_zip(url,folder):\n",
    "    try:\n",
    "        result = requests.get(url)\n",
    "        fname = result.headers['Content-Disposition'].split('\"')[1]\n",
    "        res= result.content\n",
    "        with open( folder + fname, \"wb\" ) as f :\n",
    "                f.write( res )\n",
    "        return True\n",
    "    except:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('zimuku_links.csv')\n",
    "folder = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 True\n",
      "1 True\n",
      "2 True\n",
      "3 True\n",
      "4 True\n",
      "5 True\n",
      "6 True\n",
      "7 True\n",
      "8 True\n",
      "9 True\n",
      "10 True\n",
      "11 True\n",
      "12 True\n",
      "13 True\n",
      "14 True\n",
      "15 True\n",
      "16 True\n",
      "17 True\n"
     ]
    }
   ],
   "source": [
    "#df=df.ix[:5]\n",
    "for index,row in df.iterrows():\n",
    "    try:\n",
    "        link = row['link']\n",
    "        response = download_zip(link,folder)\n",
    "        df.loc[index,'status']= response\n",
    "        print(index,response)\n",
    "    except:\n",
    "        df.loc[index,'status']= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
